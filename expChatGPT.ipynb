{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kaitlin-ho/tests/blob/main/expChatGPT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ChatGPT Valuation Consistency Experiments\n",
        "\n",
        "**ATTENTION!** Remember to change the value of the $\\texttt{AUTHKEY}$ variable below to the authorization key associated with your OpenAI account"
      ],
      "metadata": {
        "id": "9GHDW_Wm7vpi"
      },
      "id": "9GHDW_Wm7vpi"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TODO: Experiment Description"
      ],
      "metadata": {
        "id": "86eNGPNU74fs"
      },
      "id": "86eNGPNU74fs"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialization and Setup"
      ],
      "metadata": {
        "id": "rcbZPBvsvBr8"
      },
      "id": "rcbZPBvsvBr8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install and import stuff\n"
      ],
      "metadata": {
        "id": "j2skJGBovMca"
      },
      "id": "j2skJGBovMca"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e1329a8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 915
        },
        "id": "5e1329a8",
        "outputId": "5bb9e600-7454-4afc-c6e9-f4218c6024a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.12.0-py3-none-any.whl (226 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/226.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/75.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.2)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 openai-1.12.0\n",
            "Collecting preflibtools\n",
            "  Downloading preflibtools-2.0.13-py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.6/40.6 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from preflibtools) (1.23.5)\n",
            "Collecting mip (from preflibtools)\n",
            "  Downloading mip-1.15.0-py3-none-any.whl (15.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m86.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cffi==1.15.* (from mip->preflibtools)\n",
            "  Downloading cffi-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (441 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m441.8/441.8 kB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi==1.15.*->mip->preflibtools) (2.21)\n",
            "Installing collected packages: cffi, mip, preflibtools\n",
            "  Attempting uninstall: cffi\n",
            "    Found existing installation: cffi 1.16.0\n",
            "    Uninstalling cffi-1.16.0:\n",
            "      Successfully uninstalled cffi-1.16.0\n",
            "Successfully installed cffi-1.15.1 mip-1.15.0 preflibtools-2.0.13\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cffi"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import requests\n",
        "\n",
        "# for OpenAI stuff\n",
        "# !python.exe -m pip install --upgrade pip\n",
        "!pip install --upgrade openai\n",
        "from openai import OpenAI\n",
        "\n",
        "# for PrefLib\n",
        "!pip install preflibtools\n",
        "import preflibtools as pt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup access to OpenAI\n",
        "\n",
        "\n",
        "ATTENTION! Remember to change the value of the AUTHKEY variable below to the authorization key associated with your OpenAI account\n",
        "\n",
        "#### OpenAI developer account and authentication\n",
        "- Go to https://platform.openai.com/\n",
        "- Login using the Google authorization method using your binghamton.edu account\n",
        "\n",
        "#### API Authentication\n",
        "- Read documentation [here](https://platform.openai.com/docs/api-reference/authentication)\n",
        "- Set up your access key [here](https://platform.openai.com/api-keys) (requires authentication)"
      ],
      "metadata": {
        "id": "4Q7GZX8Avqud"
      },
      "id": "4Q7GZX8Avqud"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9357d57",
      "metadata": {
        "id": "e9357d57"
      },
      "outputs": [],
      "source": [
        "### !!! Change this !!! ###\n",
        "AUTHKEY = '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'\n",
        "######### !!! #############\n",
        "MODEL = \"gpt-3.5-turbo-0125\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22c5a903",
      "metadata": {
        "id": "22c5a903"
      },
      "outputs": [],
      "source": [
        "client = OpenAI(\n",
        "    # This is the default and can be omitted\n",
        "    api_key=AUTHKEY,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiments start here\n",
        "\n",
        "TODO: Move the experiments setup code to its own notebook or python file"
      ],
      "metadata": {
        "id": "me30W382ukNw"
      },
      "id": "me30W382ukNw"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Experiment setup"
      ],
      "metadata": {
        "id": "B54Llb9gu5_u"
      },
      "id": "B54Llb9gu5_u"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Assumptions:\n",
        "- Finite number of agents and items\n",
        "- Items are indivisible\n",
        "- Exactly one unit of each item is available. If there are two similar items, they are listed separately\n",
        "\n",
        "#### Conventions\n",
        "- N refers to the number of agents, and agents will be indexed by i\n",
        "- M refers to the number of items, and items will be indexed by j\n",
        "- If an agent's value for an item is non-negative, it will be referred to as a good, and otherwise it will be referred to as a chore\n",
        "- All vectors are column vectors unless clearly documented to be otherwise, i.e., a vector with k components is represented by a k x 1 array.\n",
        "- Names of agents and items are sampled without replacement"
      ],
      "metadata": {
        "id": "R-pFn-h-v9Uq"
      },
      "id": "R-pFn-h-v9Uq"
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Configuration stuff\n",
        "\"\"\"\n",
        "\n",
        "N = 2 # number of agents\n",
        "\n",
        "M = 3 # number of items\n",
        "\n",
        "num_instances = 1 # number of instances\n",
        "\n",
        "# Define different pools of agent names\n",
        "agentNamePools = {\n",
        "    'default': ['Alice', 'Bob', 'Carol']\n",
        "}\n",
        "\n",
        "# Define different pools of item names\n",
        "itemNamePools = {\n",
        "    'fruits': ['apple', 'banana', 'orange'],\n",
        "    'vegetables': ['asparagus', 'broccoli', 'potato'],\n",
        "    'gems': ['diamond', 'emerald', 'ruby'],\n",
        "    'houses': ['apartment', 'bungalow', 'villa'],\n",
        "    'cars': ['buick', 'cadillac', 'ford']\n",
        "}\n",
        "\n",
        "# Define how many names should be sampled from each pool\n",
        "agentPoolSampling = {\n",
        "    'default': 2\n",
        "}\n",
        "\n",
        "for k in agentPoolSampling.keys():\n",
        "    assert(k in agentNamePools)\n",
        "    assert(agentPoolSampling[k] <= len(agentNamePools[k]))\n",
        "assert(np.sum([agentPoolSampling[k] for k in agentPoolSampling.keys()]) == N)\n",
        "\n",
        "itemPoolSampling = {\n",
        "    'fruits': 2,\n",
        "    'vegetables': 1\n",
        "}\n",
        "\n",
        "for k in itemPoolSampling.keys():\n",
        "    assert(k in itemNamePools)\n",
        "    assert(itemPoolSampling[k] <= len(itemNamePools[k]))\n",
        "assert(np.sum([itemPoolSampling[k] for k in itemPoolSampling.keys()]) == M)\n",
        "\n",
        "print(\"good config\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGKvSA7mvxbd",
        "outputId": "ea5630d6-fbbb-4583-b071-63fe02517ec0"
      },
      "id": "zGKvSA7mvxbd",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "good config\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set Agent and Item Names"
      ],
      "metadata": {
        "id": "gE0wBJZgF_pG"
      },
      "id": "gE0wBJZgF_pG"
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Set agent and item names\n",
        "TODO: Put it in a loop to generate a large number of instances\n",
        "\"\"\"\n",
        "\n",
        "agentNames = []\n",
        "for k in agentPoolSampling.keys():\n",
        "    agentNames += random.sample(agentNamePools[k], agentPoolSampling[k])\n",
        "\n",
        "itemNames = []\n",
        "for k in itemPoolSampling.keys():\n",
        "    itemNames += random.sample(itemNamePools[k], itemPoolSampling[k])"
      ],
      "metadata": {
        "id": "x8rycs_px6_l"
      },
      "id": "x8rycs_px6_l",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set Valuations\n",
        "\n",
        "Use the Preflib python library\n",
        "See documentation [here](https://preflib.github.io/preflibtools/reference/instances/sampling.html)"
      ],
      "metadata": {
        "id": "N8MNyM3UGFNc"
      },
      "id": "N8MNyM3UGFNc"
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Set agents' valuations for items\n",
        "TODO: Put it in a loop to generate a large number of instances\n",
        "\"\"\"\n",
        "\n",
        "def generate_valuations_IC(N, M, num_instances=1, low=1, high=10):\n",
        "    \"\"\"\n",
        "    Generate instances where valuations are integers drawn from the uniform distribution over [low, high]\n",
        "    Input:\n",
        "        N: integer, number of agents\n",
        "        M: integer, number of items\n",
        "        num_instances: integer, number of instances to generate\n",
        "        low: integer, lowest possible value of an item\n",
        "        high: integer, highest possible value of an item\n",
        "    Output:\n",
        "        instances: a list of instances\n",
        "                   each instances is a 2D N x M numpy array\n",
        "                   whose i,j-th entry is the value that agent i has for item j\n",
        "    \"\"\"\n",
        "    assert(low <= high)\n",
        "    assert(num_instances > 0)\n",
        "    instances = []\n",
        "    for k in range(num_instances):\n",
        "        val = np.zeros((N, M))\n",
        "        for i in range(N):\n",
        "            for j in range(M):\n",
        "                val[i, j] = random.randint(low, high+1)\n",
        "        instances.append(val)\n",
        "    return instances"
      ],
      "metadata": {
        "id": "IVoR8_GCGJZt"
      },
      "id": "IVoR8_GCGJZt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3aeea5d",
      "metadata": {
        "id": "f3aeea5d"
      },
      "outputs": [],
      "source": [
        "instances = generate_valuations_IC(N, M)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate allocations"
      ],
      "metadata": {
        "id": "jMF-ltal_C9l"
      },
      "id": "jMF-ltal_C9l"
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Generate allocations\n",
        "TODO: More sophisticated ways to generate allocations\n",
        "\"\"\"\n",
        "\n",
        "def generate_allocation_uniform(N, M):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        N: integer, number of agents\n",
        "        M: integer, number of items\n",
        "    Output:\n",
        "        A: a 2D N x M numpy array\n",
        "           the i, j-th entry is either 1 or 0 indicating whether agent i receives item j\n",
        "    \"\"\"\n",
        "    A = np.zeros((N, M))\n",
        "    for j in range(M):\n",
        "        i = random.randint(0, N-1)\n",
        "        A[i, j] = 1\n",
        "    return A"
      ],
      "metadata": {
        "id": "AXkSNU6t_I81"
      },
      "id": "AXkSNU6t_I81",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "TODO: Put this is a loop or something appropriate to run an experiment\n",
        "\"\"\"\n",
        "A = generate_allocation_uniform(2, 3)\n",
        "allocations = []\n",
        "allocations.append(A)\n",
        "print(allocations)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMH_n38fAGOr",
        "outputId": "fac314b6-adad-43ce-f969-40ae44c7bc4c"
      },
      "id": "cMH_n38fAGOr",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([[0., 0., 1.],\n",
            "       [1., 1., 0.]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prompt Engineering"
      ],
      "metadata": {
        "id": "HqK87iHku0Ap"
      },
      "id": "HqK87iHku0Ap"
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_valuation_text(valuation, agentNames, itemNames):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        val: a 2D N x M numpy array describing a valuation profile\n",
        "             whose i,j-th entry is the value that agent i has for item j\n",
        "        agentNames: a list of strings consisting of the names of the agents\n",
        "        itemNames: a list of strings consisting of the names of the items\n",
        "    Output:\n",
        "        valText: a string which describes a valuation profile\n",
        "    \"\"\"\n",
        "    (N, M) = valuation.shape\n",
        "    assert(len(agentNames) == N)\n",
        "    assert(len(itemNames) == M)\n",
        "    valText = ''\n",
        "    agentText = f'There are {N} agents named ' + ', '.join(agentNames[:N-1]) + f' and {agentNames[N-1]}\\n'\n",
        "    valText += agentText\n",
        "    itemText  = f'There are {M} items named ' + ', '.join(itemNames[:M-1]) + f' and {itemNames[M-1]}\\n'\n",
        "    valText += itemText\n",
        "    # now, create a table describing the valuation profile in csv format\n",
        "    valTable = f'In this table, each person\\'s value for items {itemText} are listed with the assigned values.\\n'\n",
        "    valHeader = f', ' + ', '.join(itemNames) + '\\n'\n",
        "    valRows = ''\n",
        "    for i in range(N):\n",
        "        iVal = [str(valuation[i, j]) for j in range(M)]\n",
        "        valRows += agentNames[i] + ', ' + ', '.join(iVal) + '\\n'\n",
        "    valText += valTable + valHeader + valRows\n",
        "    return valText"
      ],
      "metadata": {
        "id": "WNMQAqFH3DeU"
      },
      "id": "WNMQAqFH3DeU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_allocation_text(allocation, agentNames, itemNames):\n",
        "    (N, M) = allocation.shape\n",
        "    assert(len(agentNames) == N)\n",
        "    assert(len(itemNames) == M)\n",
        "    allocText = ''\n",
        "    itemQuantText = 'There are '\n",
        "    for j in range(M-1):\n",
        "        itemQuantText += f'{np.sum(allocation[:, j])} number of {itemNames[j]}s, '\n",
        "    itemQuantText += f'and 1 {itemNames[M-1]} \\n'\n",
        "    allocText += itemQuantText\n",
        "    itemText  = f'There are {M} items named ' + ', '.join(itemNames[:M-1]) + f' and {itemNames[M-1]}\\n'\n",
        "    allocDescText = f'This table shows an allocation. Each person\\'s allocations of {itemText} are listed, with the assigned values.\\n'\n",
        "    allocHeader = f', ' + ', '.join(itemNames) + '\\n'\n",
        "    allocRows = ''\n",
        "    for i in range(N):\n",
        "        iAlloc = [str(allocation[i, j]) for j in range(M)]\n",
        "        allocRows += agentNames[i] + ', ' + ', '.join(iAlloc) + '\\n'\n",
        "    allocText += allocDescText + allocHeader + allocRows\n",
        "    return allocText"
      ],
      "metadata": {
        "id": "131Kcr_EAmJR"
      },
      "id": "131Kcr_EAmJR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Generate the prompt\n",
        "TODO:\n",
        "    Write a function that:\n",
        "        takes as input a pair of valuation and allocation\n",
        "        and outputs a query to ChatGPT\n",
        "    Put this in a loop for experiments\n",
        "\"\"\"\n",
        "queryText = ''\n",
        "valuation = instances[0]\n",
        "allocation = allocations[0]\n",
        "valText = generate_valuation_text(valuation, agentNames, itemNames)\n",
        "allocText = generate_allocation_text(allocation, agentNames, itemNames)\n",
        "queryText += valText + allocText\n",
        "queryText += f'Does {agentNames[0]} prefer their allocated items to the items {agentNames[1]} is allocation?'\n",
        "queryText += f'You may answer Yes or No. Do not explain.'\n",
        "\n",
        "print(queryText)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRMdwCR454vw",
        "outputId": "5091883b-2b15-468f-afa5-7e5034a310d3"
      },
      "id": "rRMdwCR454vw",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2 agents named Carol and Bob\n",
            "There are 3 items named orange, apple and potato\n",
            "In this table, each person's value for items There are 3 items named orange, apple and potato\n",
            " are listed with the assigned values.\n",
            ", orange, apple, potato\n",
            "Carol, 10.0, 2.0, 4.0\n",
            "Bob, 9.0, 5.0, 7.0\n",
            "There are 1.0 number of oranges, 1.0 number of apples, and 1 potato \n",
            "This table shows an allocation. Each person's allocations of There are 3 items named orange, apple and potato\n",
            " are listed, with the assigned values.\n",
            ", orange, apple, potato\n",
            "Carol, 0.0, 0.0, 1.0\n",
            "Bob, 1.0, 1.0, 0.0\n",
            "Does Carol prefer their allocated items to the items Bob is allocation?You may answer Yes or No. Do not explain.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2ac5ddf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "c2ac5ddf",
        "outputId": "5d618a69-97b6-497b-d7f6-02ea42a42dec"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RateLimitError",
          "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-27c97dcad3fe>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m chat_completion = client.chat.completions.create(\n\u001b[0m\u001b[1;32m      2\u001b[0m     messages=[\n\u001b[1;32m      3\u001b[0m         {\n\u001b[1;32m      4\u001b[0m             \u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"user\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mqueryText\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeout\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mNotGiven\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNOT_GIVEN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[0;32m--> 663\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    664\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1198\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m         )\n\u001b[0;32m-> 1200\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0mstream_cls\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_StreamT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m     ) -> ResponseT | _StreamT:\n\u001b[0;32m--> 889\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    890\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    963\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mretries\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m                 \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m                 return self._retry_request(\n\u001b[0m\u001b[1;32m    966\u001b[0m                     \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m                     \u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1011\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m   1014\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    963\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mretries\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m                 \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m                 return self._retry_request(\n\u001b[0m\u001b[1;32m    966\u001b[0m                     \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m                     \u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1011\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m   1014\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 980\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    981\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m         return self._process_response(\n",
            "\u001b[0;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
          ]
        }
      ],
      "source": [
        "chat_completion = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": queryText,\n",
        "        }\n",
        "    ],\n",
        "    model=MODEL,\n",
        ")\n",
        "\n",
        "chat_completion"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xBw_ySTHEabv"
      },
      "id": "xBw_ySTHEabv",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}